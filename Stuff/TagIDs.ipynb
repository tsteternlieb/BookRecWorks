{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28fbe0a3",
   "metadata": {},
   "source": [
    "# File for generating dataset for and training the query embedding Model\n",
    " - Lots of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7071ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theo/anaconda3/envs/prawn/lib/python3.7/site-packages/thefuzz/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import gensim.downloader as gensim_api\n",
    "corpus = gensim_api.load('text8')\n",
    "from torch.distributions import categorical\n",
    "from torch.utils import data\n",
    "import pandas as pd\n",
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import json, codecs\n",
    "import tensorflow as tf\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import collections\n",
    "import torch\n",
    "import random\n",
    "from nltk import tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9de8c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dict(df,keys,values):\n",
    "    _list = list(zip(df[keys],df[values]))\n",
    "    c = collections.defaultdict(list)\n",
    "    for a,b in _list:\n",
    "        c[a].extend([b])\n",
    "\n",
    "    for key in list(c.keys()):\n",
    "        if len(c[key]) < 2:\n",
    "            del c[key]\n",
    "    print(len(c),'c length')\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06beeeba",
   "metadata": {},
   "source": [
    "## Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "7d2781d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theo/anaconda3/envs/prawn/lib/python3.7/site-packages/gensim/models/keyedvectors.py:481: UserWarning: Adding single vectors to a KeyedVectors which grows by one each time can be costly. Consider adding in batches or preallocating to the required size.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71290"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_bt = pd.read_csv('./cleaned_books_and_tags')\n",
    "with open('dict.json') as json_file:\n",
    "    correct_word_dict = json.load(json_file)\n",
    "    \n",
    "with open('book_to_int.json') as json_file:\n",
    "    book_to_int = json.load(json_file)\n",
    "    \n",
    "with open('int_to_book.json') as json_file:\n",
    "    int_to_book = json.load(json_file)\n",
    "    \n",
    "with open('book_id_to_correct_title.json') as json_file:\n",
    "    book_id_to_correct_title = json.load(json_file)\n",
    "    \n",
    "with open('incorrect_title_to_book_id.json') as json_file:\n",
    "    incorrect_title_to_book_id = json.load(json_file)\n",
    "    \n",
    "with open('int_to_weight.json') as json_file:\n",
    "    temp = json.load(json_file)\n",
    "int_to_weight = {int(k):np.asarray(v) for k,v in temp.items()}\n",
    "    \n",
    "corpus = gensim_api.load('text8')\n",
    "model = Word2Vec(corpus)\n",
    "\n",
    "#a bit hacky but usefull later\n",
    "model.wv.add_vector(\"__null__\",[0 for i in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "96fc45b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv( 'tags.csv' )\n",
    "b = pd.read_csv( 'books.csv' )\n",
    "bt = pd.read_csv( 'book_tags.csv')\n",
    "r = pd.read_csv( 'ratings.csv' )\n",
    "r = r.merge(b[['book_id','original_title']], on = 'book_id')\n",
    "bt = bt.merge( t, on = 'tag_id' )\n",
    "bt = bt.merge( b[[ 'goodreads_book_id', 'title','book_id']], on = 'goodreads_book_id' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "17107b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>tag_id</th>\n",
       "      <th>count</th>\n",
       "      <th>tag_name</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30574</td>\n",
       "      <td>167697</td>\n",
       "      <td>to-read</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11305</td>\n",
       "      <td>37174</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11557</td>\n",
       "      <td>34173</td>\n",
       "      <td>favorites</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8717</td>\n",
       "      <td>12986</td>\n",
       "      <td>currently-reading</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>33114</td>\n",
       "      <td>12716</td>\n",
       "      <td>young-adult</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864073</th>\n",
       "      <td>999907</td>\n",
       "      <td>675614</td>\n",
       "      <td>33057</td>\n",
       "      <td>7</td>\n",
       "      <td>ya-witches</td>\n",
       "      <td>Book of Shadows (Sweep, #1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864074</th>\n",
       "      <td>999908</td>\n",
       "      <td>675614</td>\n",
       "      <td>32624</td>\n",
       "      <td>6</td>\n",
       "      <td>witches-and-magic</td>\n",
       "      <td>Book of Shadows (Sweep, #1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864075</th>\n",
       "      <td>999909</td>\n",
       "      <td>675614</td>\n",
       "      <td>32612</td>\n",
       "      <td>6</td>\n",
       "      <td>witch-books</td>\n",
       "      <td>Book of Shadows (Sweep, #1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864076</th>\n",
       "      <td>999910</td>\n",
       "      <td>675614</td>\n",
       "      <td>32625</td>\n",
       "      <td>5</td>\n",
       "      <td>witches-and-warlocks</td>\n",
       "      <td>Book of Shadows (Sweep, #1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864077</th>\n",
       "      <td>999911</td>\n",
       "      <td>675614</td>\n",
       "      <td>32635</td>\n",
       "      <td>5</td>\n",
       "      <td>witchy-fiction</td>\n",
       "      <td>Book of Shadows (Sweep, #1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>864078 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  goodreads_book_id  tag_id   count              tag_name  \\\n",
       "0                0                  1   30574  167697               to-read   \n",
       "1                1                  1   11305   37174               fantasy   \n",
       "2                2                  1   11557   34173             favorites   \n",
       "3                3                  1    8717   12986     currently-reading   \n",
       "4                4                  1   33114   12716           young-adult   \n",
       "...            ...                ...     ...     ...                   ...   \n",
       "864073      999907             675614   33057       7            ya-witches   \n",
       "864074      999908             675614   32624       6     witches-and-magic   \n",
       "864075      999909             675614   32612       6           witch-books   \n",
       "864076      999910             675614   32625       5  witches-and-warlocks   \n",
       "864077      999911             675614   32635       5        witchy-fiction   \n",
       "\n",
       "                                                    title  \n",
       "0       Harry Potter and the Half-Blood Prince (Harry ...  \n",
       "1       Harry Potter and the Half-Blood Prince (Harry ...  \n",
       "2       Harry Potter and the Half-Blood Prince (Harry ...  \n",
       "3       Harry Potter and the Half-Blood Prince (Harry ...  \n",
       "4       Harry Potter and the Half-Blood Prince (Harry ...  \n",
       "...                                                   ...  \n",
       "864073                        Book of Shadows (Sweep, #1)  \n",
       "864074                        Book of Shadows (Sweep, #1)  \n",
       "864075                        Book of Shadows (Sweep, #1)  \n",
       "864076                        Book of Shadows (Sweep, #1)  \n",
       "864077                        Book of Shadows (Sweep, #1)  \n",
       "\n",
       "[864078 rows x 6 columns]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_bt = cleaned_bt.merge( b[[ 'goodreads_book_id']], on = 'goodreads_book_id' )\n",
    "cleaned_bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "a84cba2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "book_id_to_correct_title = dict(zip(r.book_id,r.original_title))\n",
    "incorrect_title_to_book_id = dict(zip(bt.title, bt.book_id))\n",
    "\n",
    "book_id_to_correct_title_r = dict(zip(r.original_title, r.book_id))\n",
    "for key,value in book_id_to_correct_title_r.items():\n",
    "    if key not in incorrect_title_to_book_id.keys():\n",
    "        incorrect_title_to_book_id[key] = value\n",
    "\n",
    "cleaned_bt.title = cleaned_bt.title.apply(lambda x: book_id_to_correct_title[incorrect_title_to_book_id[x]]) #fix naming\n",
    "r.original_title = r.original_title.apply(lambda x: book_id_to_correct_title[incorrect_title_to_book_id[x]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "2c11d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_bt_by_count = cleaned_bt.sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "5ae6f3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_tags = (cleaned_bt_by_count['tag_name'][cleaned_bt['count'] < 2000].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "fe4e671d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9255 c length\n"
     ]
    }
   ],
   "source": [
    "cleaned_bt.dropna(inplace=True)\n",
    "title_to_tag = gen_dict(cleaned_bt,'title','tag_name')\n",
    "for title,tags in title_to_tag.items():\n",
    "    new_tags = [tag for tag in tags if tag in good_tags]\n",
    "    title_to_tag[title] = new_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "3e2579d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryFromTags(tag_list, q_length, correct_word_dict, \n",
    "                  w2v=model, \n",
    "                  distribution_over_length = None, sample_similar_prob = .3):\n",
    "    '''\n",
    "    function for generating a synthetic query.\n",
    "    odds_per_count is the distribution over various sentence lengthes to sample from.\n",
    "    distribution_over_vocab is some distribution over tags to be sampled from.\n",
    "    '''\n",
    "    total_vocab = w2v.wv.key_to_index.keys()\n",
    "    #max_q_length = min(len(tag_list),max_q_length)\n",
    "    \n",
    "    \n",
    "    if distribution_over_length == None:\n",
    "        distribution_over_length = categorical.Categorical(probs = torch.ones(q_length)/q_length)\n",
    "\n",
    "    query_words = []\n",
    "    tag_list = random.sample(tag_list,30)\n",
    "    single_tags = []\n",
    "    for tag in tag_list:\n",
    "        single_tags.extend(tag.split('-'))\n",
    "        \n",
    "    single_tags = list(filter(lambda tag: len(tag)>2, single_tags))\n",
    "    single_tags = list(set(single_tags))\n",
    "    for i,tag in enumerate(single_tags):\n",
    "        if tag in correct_word_dict.keys():\n",
    "            single_tags[i] = correct_word_dict[tag][0]\n",
    "\n",
    "    out = random.sample(single_tags,q_length)\n",
    "    return out\n",
    "    \n",
    "    \n",
    "    return random.choices(query_words,k=q_length)\n",
    "    \n",
    "def query_wrapper(q_length, correct_word_dict, w2v, distribution_over_length=None, sample_similar_prob =.2):\n",
    "    return lambda tag_list: queryFromTags(tag_list,q_length,correct_word_dict,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "061d0c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(data.Dataset):\n",
    "    '''Dataset for returning (book, text) pairs\n",
    "       Somewhat overkill seeing as the database is just in memory already,\n",
    "       but could rewrite __getitem__ method for reading from disc \n",
    "       and use a few workers for fast collection.\n",
    "    '''\n",
    "    def __init__(self, title_to_tag, query_gen, book_vectors,book_to_int,int_to_book, w2v):\n",
    "        self.title_to_tag = title_to_tag       \n",
    "        self.query_gen = query_gen        \n",
    "        self.book_vectors = book_vectors\n",
    "        \n",
    "        self.w2v = w2v\n",
    "        \n",
    "        #self.max_seq_length = max_seq_length\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.title_to_tag)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        title = list(title_to_tag.keys())[idx]\n",
    "        \n",
    "        tags = self.title_to_tag[title]\n",
    "        tag_list = self.query_gen(tags)\n",
    "#         num_tags = min(self.max_seq_length,len(tag_list))\n",
    "#         num_tags = self.max_seq_length\n",
    "        \n",
    "        \n",
    "#         if len(tag_list) >= self.max_seq_length:\n",
    "#             tag_list = tag_list[:self.max_seq_length]\n",
    "#         else:\n",
    "#             tag_list.extend(['__null__' for _ in range(self.max_seq_length-len(tag_list))])\n",
    "        [self.w2v.wv[tag] for tag in tag_list]\n",
    "        return torch.tensor([self.w2v.wv[tag] for tag in tag_list]).float(), torch.tensor(self.book_vectors[book_to_int[title]]).float()\n",
    "        \n",
    "        tag_vectors = torch.tensor([self.w2v.wv[tag] for tag in tag_list])\n",
    "        book_vector = torch.tensor(self.book_vectors[book_to_int[title]])\n",
    "        \n",
    "        attention_mask = torch.tensor([-1 for _ in range(num_tags)] + [0 for _ in range(self.max_seq_length-num_tags)])\n",
    "        \n",
    "    \n",
    "        return ((tag_vectors.float(), attention_mask.float()), book_vector.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "52c1b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customLoader(dataset,batch_size):\n",
    "    length = len(dataset)\n",
    "    indices = list(range(length))\n",
    "    random.shuffle(indices)\n",
    "    idx = 0\n",
    "    while True:\n",
    "        if idx + batch_size > length:\n",
    "            idx = 0\n",
    "            random.shuffle(indices)\n",
    "            \n",
    "        batch = [dataset[indices[i]] for i in range(idx,idx+batch_size)]\n",
    "        X,Y = zip(*batch)\n",
    "        \n",
    "        yield torch.stack(X,dim = 0), torch.stack(Y,dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "0bacca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEmbed(torch.nn.Module):\n",
    "    '''\n",
    "    TransformerEncoder for word embeddings. Since the synthetic queries are generated with out any type of order,\n",
    "    we don't use a positional encoding.\n",
    "    '''\n",
    "    def __init__(self, in_dim, out_dim, transformer_dim=512):\n",
    "        super(TransformerEmbed, self).__init__()\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=transformer_dim, nhead=8,batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=3)\n",
    "        \n",
    "        self.initial = nn.Linear(in_dim,transformer_dim)\n",
    "        self.final = nn.Linear(transformer_dim, out_dim)\n",
    "        self.float()\n",
    "    def call(self, inputs):\n",
    "        x = self.initial(inputs)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = torch.mean(x,dim=1)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        x = self.final(x)\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "83dd9e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainWrapper():\n",
    "    '''\n",
    "    wrapper for handling training\n",
    "    '''\n",
    "    def __init__(self, model, lr, dataset, batch_size):\n",
    "        self.model = model\n",
    "        self.optim = torch.optim.Adam(self.model.parameters(), lr = lr)\n",
    "        self.batch_generator = customLoader(dataset,batch_size)\n",
    "        self.model.float()\n",
    "        \n",
    "    def Train(self,num_epochs, num_steps_per_epoch):\n",
    "        for epoch in range(num_epochs):\n",
    "            for step in range(num_steps_per_epoch):\n",
    "                loss = self.__train()\n",
    "                print(loss)\n",
    "                \n",
    "    def __train(self):\n",
    "        x, Y = next(self.batch_generator)\n",
    "       \n",
    "        self.optim.zero_grad()\n",
    "\n",
    "        out = self.model.call(x)\n",
    "        \n",
    "        loss = self.loss(out,Y)\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "        \n",
    "        return loss.detach()\n",
    "        \n",
    "    def loss(self,out,labels):\n",
    "        #print(labels.shape)\n",
    "        return nn.MSELoss()(out,labels)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "be0b8cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TransformerEmbed(100,80)\n",
    "trainWrapper = TrainWrapper(transformer,3e-4,textData,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "4b357dba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainWrapper.Train(30,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "00c750af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_vector(query,model,word2vec):\n",
    "    query = torch.tensor([[word2vec.wv[q] for q in query]])\n",
    "    return model.call(query)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "94653e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(transformer.state_dict(), './query_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
